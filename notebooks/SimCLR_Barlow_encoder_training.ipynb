{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMp5lKNjgBXq"
      },
      "source": [
        "## Initial setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDVgw5FnT6Hc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIYdn1woOS1n",
        "outputId": "9ae27287-05db-4c3f-f9af-120a888a6958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0\n",
            "1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "# tensorflow version used is 2.7.0\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "# torch version used is 1.10+cu111"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZowsDvOYK37",
        "outputId": "afda6796-40cb-4528-cc37-541230a786bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Feb 19 13:59:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "421MrJNMYQD7",
        "outputId": "289c5832-a767-42b0-dafd-01d0ec0e856e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.16.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.7/dist-packages (0.24.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.24.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_io) (0.24.0)\n"
          ]
        }
      ],
      "source": [
        "# Other imports\n",
        "! pip install tensorflow_addons\n",
        "! pip install tensorflow_io\n",
        "\n",
        "import os\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow import keras as tfkeras\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_io as tfio\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity as cos\n",
        "from sympy.utilities.iterables import multiset_permutations\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import zipfile\n",
        "import concurrent.futures\n",
        "\n",
        "# Random seed fix\n",
        "random_seed = 42\n",
        "tf.random.set_seed(random_seed)\n",
        "np.random.seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUFlGxuJgBX9"
      },
      "source": [
        "## Dataset gathering and preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA5y9EDOx5Lo"
      },
      "outputs": [],
      "source": [
        "training_batch_size = 64\n",
        "\n",
        "imageSize=224\n",
        "method = \"simclr\"             # \"simclr\" or \"barlow\"\n",
        "source = \"ImageNet\"           # \"ImageNet\" or \"TEM\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaI1LQwZClX3",
        "outputId": "5a5fc3fc-87f8-43d5-bbd6-291f6e4c1bcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n",
            "832\n"
          ]
        }
      ],
      "source": [
        "if source == \"ImageNet\":\n",
        "  Imagenet_images_train = list(paths.list_images(\"/content/drive/MyDrive/TEM image datasets/2022-1000-ImageNet\"))\n",
        "  train_images_directory_select = np.random.choice(Imagenet_images_train, 832, replace=False)\n",
        "  print(len(Imagenet_images_train))\n",
        "  print(len(train_images_directory_select))\n",
        "\n",
        "if source == \"TEM\":\n",
        "  CEM_images_train = list(paths.list_images(\"/content/drive/MyDrive/TEM image datasets/2021-CEM500K/jpg\"))\n",
        "  train_images_directory_select = np.random.choice(CEM_images_train, 832, replace=False)\n",
        "  print(len(CEM_images_train))\n",
        "  print(len(train_images_directory_select))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMkDpqWQDwuN"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/nanowire-morphology-classification-project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad9dX7ONYV9Y"
      },
      "outputs": [],
      "source": [
        "# Augmentation utilities (differs from the original implementation)\n",
        "# Adapted from: https://arxiv.org/pdf/2002.05709.pdf (Appendxi A) \n",
        "# corresponding GitHub: https://github.com/google-research/simclr/)\n",
        "\n",
        "class CustomAugment(object):\n",
        "    def __call__(self, sample):        \n",
        "\n",
        "        # Random flips\n",
        "        sample = self._random_apply(tf.image.flip_left_right, sample, p=0.5)\n",
        "\n",
        "        # Random crop always\n",
        "        sample = self._random_apply(self._random_crop, sample, p=1.0)\n",
        "        \n",
        "        # Randomly apply transformation (color distortions) with probability p.\n",
        "        sample = self._random_apply(self._color_jitter, sample, p=0.8)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def _random_crop(self, x):\n",
        "        \n",
        "        # distance from left to right, from bottom to top\n",
        "        l = tf.random.uniform([], minval=int(imageSize * 0.25), maxval=int(imageSize * 0.5), dtype=tf.int32)             # 25 as min bound, so that the cropped images are not too small\n",
        "        # l = int(0.5 * imageSize)                                                                              # use this line if the crop box size is constant\n",
        "\n",
        "        # lower left corner\n",
        "        y1 = tf.random.uniform([], minval=0, maxval= imageSize - 1 - l, dtype=tf.int32)\n",
        "        x1 = tf.random.uniform([], minval=0, maxval= imageSize - 1 - l, dtype=tf.int32)\n",
        "        \n",
        "        x = tf.image.crop_to_bounding_box(x, y1, x1, l, l)\n",
        "        x = tf.image.resize(x, size=[imageSize, imageSize])\n",
        "        return x\n",
        "\n",
        "    def _color_jitter(self, x, s=1):\n",
        "        # one can also shuffle the order of following augmentations\n",
        "        # each time they are applied.\n",
        "        # x = tf.image.random_brightness(x, max_delta=0.2*s)                 \n",
        "        x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "        x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "        x = tf.image.random_hue(x, max_delta=0.2*s)\n",
        "        x = tf.clip_by_value(x, 0, 1)\n",
        "        return x\n",
        "    \n",
        "    def _random_apply(self, func, x, p):\n",
        "        return tf.cond(\n",
        "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                  tf.cast(p, tf.float32)),\n",
        "          lambda: func(x),\n",
        "          lambda: x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKYH6UxnYa7g"
      },
      "outputs": [],
      "source": [
        "# Build the augmentation pipeline\n",
        "data_augmentation = Sequential([Lambda(CustomAugment())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eDTVhuHYdwi"
      },
      "outputs": [],
      "source": [
        "# Image preprocessing utils\n",
        "@tf.function\n",
        "def parse_images(image_path):\n",
        "    image_string = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, size=[imageSize, imageSize])\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otqf-I5FZLqd"
      },
      "outputs": [],
      "source": [
        "# Create TensorFlow dataset for training\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(train_images_directory_select)\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .map(parse_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    .batch(training_batch_size\n",
        "           , drop_remainder=True\n",
        "           )\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2avjHJzRgBYS"
      },
      "source": [
        "## Initiate our self-supervised model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZwRlS-39B8y"
      },
      "outputs": [],
      "source": [
        "Resnet50_transfer = tf.keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(imageSize, imageSize, 3), \n",
        "    pooling=None,\n",
        ")\n",
        "\n",
        "Resnet50_transfer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1_Wl0DzZQ5F"
      },
      "outputs": [],
      "source": [
        "# Architecture for resnet as base architecture\n",
        "def get_resnet_self_supervise_model(hidden_1, hidden_2, hidden_3):\n",
        "    base_model = Resnet50_transfer\n",
        "    base_model.trainable = True\n",
        "    inputs = Input((imageSize, imageSize, 3))\n",
        "    h = base_model(inputs, training=True)\n",
        "    h = GlobalAveragePooling2D()(h)\n",
        "\n",
        "    projection_1 = Dense(hidden_1)(h)                                        \n",
        "    projection_1 = Activation(\"relu\")(projection_1)\n",
        "    projection_1 = BatchNormalization(epsilon=0.001)(projection_1)\n",
        "    projection_2 = Dense(hidden_2)(projection_1)\n",
        "    projection_2 = Activation(\"relu\")(projection_2)\n",
        "    projection_2 = BatchNormalization(epsilon=0.001)(projection_2)\n",
        "    projection_3 = Dense(hidden_3)(projection_2)\n",
        "    projection_3 = BatchNormalization(epsilon=0.001)(projection_3)\n",
        "\n",
        "    resnet_model = Model(inputs, projection_3)\n",
        "    \n",
        "    return resnet_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNUAPhnM07Yo"
      },
      "source": [
        "## Training self-supervised model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6qPdhPrZpFA"
      },
      "outputs": [],
      "source": [
        "#### use this train_step block for Simclr implementation\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "@tf.function\n",
        "def train_step_simclr(xis, xjs, model, optimizer, criterion, temperature):\n",
        "    with tf.GradientTape() as tape:\n",
        "        projections_1_original = model(xis)\n",
        "        projections_2_original = model(xjs)\n",
        "\n",
        "        # simclr derivatives uses layer norm\n",
        "        # normalize projection feature vectors            along the feature dimension, this is a l2_norm\n",
        "        projections_1 = tf.math.l2_normalize(projections_1_original, axis=1)\n",
        "        projections_2 = tf.math.l2_normalize(projections_2_original, axis=1)\n",
        "        similarities = (tf.matmul(projections_1, projections_2, transpose_b=True) / temperature)\n",
        "\n",
        "        # the temperature-scaled similarities are used as logits for cross-entropy\n",
        "        contrastive_labels = tf.range(training_batch_size)\n",
        "        loss = criterion(\n",
        "            tf.concat([contrastive_labels, contrastive_labels], axis=0),\n",
        "            tf.concat([similarities, tf.transpose(similarities)], axis=0))\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_m9albOUK5VW"
      },
      "outputs": [],
      "source": [
        "#### use this train_step block for Barlow-Twins implementation\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "@tf.function\n",
        "def train_step_barlow(xis, xjs, model, optimizer, criterion, temperature):\n",
        "    with tf.GradientTape() as tape:\n",
        "        projections_1_original = model(xis)\n",
        "        projections_2_original = model(xjs)\n",
        "\n",
        "        # batchnorm for barlow twins\n",
        "        # use these two lines when doing mini-batch gradient descent\n",
        "        projections_1 = (projections_1_original - tf.reduce_mean(projections_1_original, axis=0)) / tf.math.reduce_std(projections_1_original, axis=0)\n",
        "        projections_2 = (projections_2_original - tf.reduce_mean(projections_2_original, axis=0)) / tf.math.reduce_std(projections_2_original, axis=0)\n",
        "\n",
        "        # use these two lines when doing stochastic gradient descent (i.e. batch size = 1)\n",
        "        # projections_1 = projections_1_original\n",
        "        # projections_2 = projections_2_original\n",
        "\n",
        "        # the cross correlation of image representations should be the identity matrix\n",
        "\n",
        "        feature_dim = tf.cast(tf.shape(projections_1)[1], tf.float32)\n",
        "        cross_correlation = (tf.matmul(projections_1, projections_2, transpose_a=True) / training_batch_size)\n",
        "        target_cross_correlation = tf.eye(feature_dim)\n",
        "        squared_errors = (target_cross_correlation - cross_correlation) ** 2\n",
        "\n",
        "        # invariance loss = average diagonal error\n",
        "        # redundancy reduction loss = average off-diagonal error\n",
        "        invariance_loss = (tf.reduce_sum(squared_errors * tf.eye(feature_dim)) / feature_dim)\n",
        "        redundancy_reduction_loss = tf.reduce_sum(squared_errors * (1 - tf.eye(feature_dim))) / (feature_dim * (feature_dim - 1))\n",
        "\n",
        "        # use redundancy_redunction_weight of 0.005 from the paper, not a sensitive parameter\n",
        "        loss = invariance_loss + 0.005 * redundancy_reduction_loss\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfp8gT4ZZtif"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataset, optimizer, criterion,\n",
        "                 temperature, epochs=100):\n",
        "    step_wise_loss = []\n",
        "    epoch_wise_loss = []\n",
        "\n",
        "    epoch = 1\n",
        "    for k in tqdm(range(epochs)):\n",
        "      i = 0\n",
        "      for image_batch in dataset:\n",
        "          a = data_augmentation(image_batch)\n",
        "          b = data_augmentation(image_batch)\n",
        "\n",
        "          if method == \"simclr\":\n",
        "            loss = train_step_simclr(a, b, model, optimizer, criterion, temperature)\n",
        "          if method == \"barlow\":\n",
        "            loss = train_step_barlow(a, b, model, optimizer, criterion, temperature)\n",
        "          step_wise_loss.append(loss)\n",
        "          i += 1\n",
        "          print(\"batch: {} loss: {:.5f}\".format(i, np.mean(step_wise_loss)))\n",
        "\n",
        "      epoch_wise_loss.append(np.mean(step_wise_loss))\n",
        "      if epoch % 20 == 0:\n",
        "        model.save_weights('%s_%s_batch%i_project128_64_1024_seed%i.h5' % (method, source, training_batch_size, random_seed))\n",
        "        print(\"epoch: {} loss: {:.5f}\".format(epoch, np.mean(step_wise_loss)))\n",
        "      epoch += 1\n",
        "          \n",
        "\n",
        "    return epoch_wise_loss, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QKAoeXwJZ5S1",
        "outputId": "77654b13-7b40-434a-a7dc-de9591ef0f9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 1 loss: 0.57619\n",
            "batch: 2 loss: 0.43121\n",
            "batch: 3 loss: 0.45222\n",
            "batch: 4 loss: 0.39469\n",
            "batch: 5 loss: 0.38681\n",
            "batch: 6 loss: 0.33074\n",
            "batch: 7 loss: 0.35192\n",
            "batch: 8 loss: 0.34164\n",
            "batch: 9 loss: 0.35104\n",
            "batch: 10 loss: 0.36822\n",
            "batch: 11 loss: 0.36665\n",
            "batch: 12 loss: 0.35966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/200 [11:33<38:21:06, 693.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.33729\n",
            "batch: 1 loss: 0.32755\n",
            "batch: 2 loss: 0.34130\n",
            "batch: 3 loss: 0.33533\n",
            "batch: 4 loss: 0.32271\n",
            "batch: 5 loss: 0.31440\n",
            "batch: 6 loss: 0.31166\n",
            "batch: 7 loss: 0.29918\n",
            "batch: 8 loss: 0.28848\n",
            "batch: 9 loss: 0.27715\n",
            "batch: 10 loss: 0.27190\n",
            "batch: 11 loss: 0.28531\n",
            "batch: 12 loss: 0.27678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 2/200 [22:50<37:36:52, 683.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.27652\n",
            "batch: 1 loss: 0.27942\n",
            "batch: 2 loss: 0.28107\n",
            "batch: 3 loss: 0.27381\n",
            "batch: 4 loss: 0.26927\n",
            "batch: 5 loss: 0.26277\n",
            "batch: 6 loss: 0.25918\n",
            "batch: 7 loss: 0.25793\n",
            "batch: 8 loss: 0.25574\n",
            "batch: 9 loss: 0.24996\n",
            "batch: 10 loss: 0.24518\n",
            "batch: 11 loss: 0.24362\n",
            "batch: 12 loss: 0.23837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 3/200 [34:09<37:17:54, 681.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.23610\n",
            "batch: 1 loss: 0.23580\n",
            "batch: 2 loss: 0.23282\n",
            "batch: 3 loss: 0.22809\n",
            "batch: 4 loss: 0.22476\n",
            "batch: 5 loss: 0.22062\n",
            "batch: 6 loss: 0.21746\n",
            "batch: 7 loss: 0.21734\n",
            "batch: 8 loss: 0.21505\n",
            "batch: 9 loss: 0.21278\n",
            "batch: 10 loss: 0.21072\n",
            "batch: 11 loss: 0.20777\n",
            "batch: 12 loss: 0.20842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 4/200 [45:34<37:11:09, 683.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.20911\n",
            "batch: 1 loss: 0.20676\n",
            "batch: 2 loss: 0.20360\n",
            "batch: 3 loss: 0.20137\n",
            "batch: 4 loss: 0.19841\n",
            "batch: 5 loss: 0.19752\n",
            "batch: 6 loss: 0.19467\n",
            "batch: 7 loss: 0.19474\n",
            "batch: 8 loss: 0.19202\n",
            "batch: 9 loss: 0.18932\n",
            "batch: 10 loss: 0.18666\n",
            "batch: 11 loss: 0.18378\n",
            "batch: 12 loss: 0.18168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▎         | 5/200 [57:01<37:04:26, 684.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.17976\n",
            "batch: 1 loss: 0.17924\n",
            "batch: 2 loss: 0.17720\n",
            "batch: 3 loss: 0.17774\n",
            "batch: 4 loss: 0.17523\n",
            "batch: 5 loss: 0.17427\n",
            "batch: 6 loss: 0.17216\n",
            "batch: 7 loss: 0.17020\n",
            "batch: 8 loss: 0.16820\n",
            "batch: 9 loss: 0.16731\n",
            "batch: 10 loss: 0.16708\n",
            "batch: 11 loss: 0.16545\n",
            "batch: 12 loss: 0.16392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 6/200 [1:08:44<37:13:16, 690.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.16309\n",
            "batch: 1 loss: 0.16115\n",
            "batch: 2 loss: 0.16031\n",
            "batch: 3 loss: 0.15966\n",
            "batch: 4 loss: 0.15798\n",
            "batch: 5 loss: 0.15774\n",
            "batch: 6 loss: 0.15649\n",
            "batch: 7 loss: 0.15519\n",
            "batch: 8 loss: 0.15473\n",
            "batch: 9 loss: 0.15320\n",
            "batch: 10 loss: 0.15180\n",
            "batch: 11 loss: 0.15050\n",
            "batch: 12 loss: 0.14895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▎         | 7/200 [1:20:29<37:16:23, 695.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.14764\n",
            "batch: 1 loss: 0.14642\n",
            "batch: 2 loss: 0.14534\n",
            "batch: 3 loss: 0.14427\n",
            "batch: 4 loss: 0.14284\n",
            "batch: 5 loss: 0.14209\n",
            "batch: 6 loss: 0.14105\n",
            "batch: 7 loss: 0.14056\n",
            "batch: 8 loss: 0.13948\n",
            "batch: 9 loss: 0.13827\n",
            "batch: 10 loss: 0.13721\n",
            "batch: 11 loss: 0.13623\n",
            "batch: 12 loss: 0.13502\n",
            "batch: 13 loss: 0.13429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 8/200 [1:32:51<37:52:23, 710.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 1 loss: 0.13313\n",
            "batch: 2 loss: 0.13211\n",
            "batch: 3 loss: 0.13158\n",
            "batch: 4 loss: 0.13055\n",
            "batch: 5 loss: 0.12949\n",
            "batch: 6 loss: 0.12854\n",
            "batch: 7 loss: 0.12752\n",
            "batch: 8 loss: 0.12647\n",
            "batch: 9 loss: 0.12582\n",
            "batch: 10 loss: 0.12489\n",
            "batch: 11 loss: 0.12422\n",
            "batch: 12 loss: 0.12546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 9/200 [1:44:56<37:55:59, 714.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.12449\n",
            "batch: 1 loss: 0.12360\n",
            "batch: 2 loss: 0.12267\n",
            "batch: 3 loss: 0.12226\n",
            "batch: 4 loss: 0.12221\n",
            "batch: 5 loss: 0.12178\n",
            "batch: 6 loss: 0.12156\n",
            "batch: 7 loss: 0.12094\n",
            "batch: 8 loss: 0.12008\n",
            "batch: 9 loss: 0.11936\n",
            "batch: 10 loss: 0.11854\n",
            "batch: 11 loss: 0.11779\n",
            "batch: 12 loss: 0.11741\n",
            "batch: 13 loss: 0.11754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 10/200 [1:57:18<38:10:26, 723.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 1 loss: 0.11689\n",
            "batch: 2 loss: 0.11614\n",
            "batch: 3 loss: 0.11538\n",
            "batch: 4 loss: 0.11458\n",
            "batch: 5 loss: 0.11444\n",
            "batch: 6 loss: 0.11371\n",
            "batch: 7 loss: 0.11293\n",
            "batch: 8 loss: 0.11231\n",
            "batch: 9 loss: 0.11165\n",
            "batch: 10 loss: 0.11144\n",
            "batch: 11 loss: 0.11155\n",
            "batch: 12 loss: 0.11085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 11/200 [2:09:18<37:54:46, 722.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.11027\n",
            "batch: 1 loss: 0.11002\n",
            "batch: 2 loss: 0.10948\n",
            "batch: 3 loss: 0.10879\n",
            "batch: 4 loss: 0.10941\n",
            "batch: 5 loss: 0.10988\n",
            "batch: 6 loss: 0.11054\n",
            "batch: 7 loss: 0.11070\n",
            "batch: 8 loss: 0.11029\n",
            "batch: 9 loss: 0.10982\n",
            "batch: 10 loss: 0.10929\n",
            "batch: 11 loss: 0.10888\n",
            "batch: 12 loss: 0.10856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 12/200 [2:21:13<37:36:00, 720.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.10822\n",
            "batch: 1 loss: 0.10772\n",
            "batch: 2 loss: 0.10748\n",
            "batch: 3 loss: 0.10699\n",
            "batch: 4 loss: 0.10653\n",
            "batch: 5 loss: 0.10756\n",
            "batch: 6 loss: 0.10694\n",
            "batch: 7 loss: 0.10635\n",
            "batch: 8 loss: 0.10574\n",
            "batch: 9 loss: 0.10526\n",
            "batch: 10 loss: 0.10480\n",
            "batch: 11 loss: 0.10450\n",
            "batch: 12 loss: 0.10398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 13/200 [2:32:56<37:07:57, 714.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.10352\n",
            "batch: 1 loss: 0.10295\n",
            "batch: 2 loss: 0.10258\n",
            "batch: 3 loss: 0.10211\n",
            "batch: 4 loss: 0.10166\n",
            "batch: 5 loss: 0.10121\n",
            "batch: 6 loss: 0.10090\n",
            "batch: 7 loss: 0.10036\n",
            "batch: 8 loss: 0.10023\n",
            "batch: 9 loss: 0.09988\n",
            "batch: 10 loss: 0.09948\n",
            "batch: 11 loss: 0.09897\n",
            "batch: 12 loss: 0.09883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 14/200 [2:44:39<36:45:24, 711.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.09841\n",
            "batch: 1 loss: 0.09804\n",
            "batch: 2 loss: 0.09791\n",
            "batch: 3 loss: 0.09746\n",
            "batch: 4 loss: 0.09700\n",
            "batch: 5 loss: 0.09752\n",
            "batch: 6 loss: 0.09725\n",
            "batch: 7 loss: 0.09687\n",
            "batch: 8 loss: 0.09680\n",
            "batch: 9 loss: 0.09636\n",
            "batch: 10 loss: 0.09590\n",
            "batch: 11 loss: 0.09586\n",
            "batch: 12 loss: 0.09547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 15/200 [2:56:25<36:27:56, 709.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 13 loss: 0.09537\n",
            "batch: 1 loss: 0.09499\n",
            "batch: 2 loss: 0.09454\n",
            "batch: 3 loss: 0.09417\n"
          ]
        }
      ],
      "source": [
        "criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) \n",
        "\n",
        "# the learning rate decay schedule in the original implementation of SimCLR and Barlow-Twins\n",
        "decay_steps = 1000\n",
        "lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
        "    initial_learning_rate=0.2, decay_steps=decay_steps)\n",
        "optimizer = tf.keras.optimizers.SGD(lr_decayed_fn)\n",
        "\n",
        "training_model = get_resnet_self_supervise_model(128, 64, 1024)\n",
        "\n",
        "epoch_wise_loss, resnet_model  = train_model(training_model, train_ds, optimizer, criterion,\n",
        "                 temperature=0.1, epochs=200)\n",
        "\n",
        "plt.plot(epoch_wise_loss)\n",
        "plt.title(\"training loss versus epochs\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "dIgqx4HqehN0",
        "outputId": "6e1338b4-ba37-4d1e-bdb7-8e66336e1b54"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(epoch_wise_loss)\n",
        "plt.title(\"training loss versus epochs\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "SimCLR_Barlow_encoder_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}